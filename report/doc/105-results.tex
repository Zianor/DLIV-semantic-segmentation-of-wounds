\section{Results and Evaluation}

In the following, the results and contribution of this project's work are summarised, and further research fields are named.

\subsection{Re-implementation and evaluation of WSNet}

The first contribution of this project is the re-implementation of the WSNet framework in a more structured and parametrised manner, such that a reconstruction of results is more accessible and does not need to make so many assumptions about unknown factors. This includes proper documentation of the code, which was lacking in the original WSNet code. During this, discrepancies between the described procedure in the paper and the available code were identified and described.

In the second step, the results were reproduced as far as possible. This showed that the proposed new "state-of-the-art" architecture does not significantly increase performance. The global state-of-the-art methods already aim to include localised information and are state-of-the-art segmentation models because of this. Further localisation creates a hidden assumption that the context size of interest is not necessarily transferable to different data sets. Further research could include changing the parameters, e.g., the number of skip connections of the models used, to improve the results.

\subsection{Assessment of the proposed Global-Local Architecture}

The proposed Global-Local Architecture is assessed in various settings. The general result is that it does not necessarily improve the performance of models. It shows that reported results in papers are not generally trustworthy. Further research on improving wound segmentation should not focus on including local information on a pre-set context size but aim to adapt state-of-the-art models for wound segmentation by exploiting the model architectures themselves.

\subsection{Robustness of wound segmentation}

The pursued experiments revealed that the performed augmentations on the training data are not sufficient to ensure that the trained models are transferable to other data sets. This was supported by experiments manually augmenting test data and testing already trained models on a different data set. More diverse and generally a higher amount of training data is required to deploy a segmentation model in a clinical context. Further research could include investigations on whether combining different data sets improves the results.